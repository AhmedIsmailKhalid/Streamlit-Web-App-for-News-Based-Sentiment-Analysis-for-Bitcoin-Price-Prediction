{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoinDesk <Response [200]> Aug 4 2021 11:31 AM  2\n",
      "CoinDesk <Response [200]> Jan 31 2022 11:30 PM  47\n",
      "CoinDesk <Response [200]> Feb 1 2022 7:55 AM  9\n",
      "BitcoinMagazine <Response [200]> 2022-02-18T09:10:09-05:00 21\n",
      "BitcoinMagazine <Response [200]> 2022-02-17T20:00:00-05:00 76\n",
      "CryptoSlate <Response [200]> Feb. 18, 2022  11:30 am 24\n",
      "CryptoSlate <Response [200]> Feb. 17, 2022  6:00 pm 35\n",
      "Yahoo <Response [200]> 2021-06-22T14:06:07.000Z 27\n",
      "Forbes <Response [200]> Jul 12 2021 08:14am  11\n",
      "NullTx <Response [200]> 2022-01-22T18:54:40+00:00 16\n",
      "NullTx <Response [200]> 2022-01-21T22:43:27+00:00 27\n",
      "Blockonomi <Response [200]> 2022-03-01T16:35:06+00:00 20\n",
      "Blockonomi <Response [200]> 2022-02-18T11:05:00+00:00 72\n",
      "Blockonomi <Response [200]> 2022-01-21T11:32:22+00:00 23\n"
     ]
    }
   ],
   "source": [
    "links = pd.read_csv('link.csv', header=None)\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept\": \n",
    "\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"Accept-Language\": \"en-US,en;q=0.5\", \"Accept-Encoding\": \"gzip, deflate\", \"DNT\": \"1\", \"Connection\": \"close\", \"Upgrade-Insecure-Requests\": \"1\"}\n",
    "\n",
    "articles = []\n",
    "dates = []\n",
    "count = 0\n",
    "\n",
    "\n",
    "for link in links[0] :\n",
    "    URL = link\n",
    "\n",
    "    page = requests.get(URL, headers=headers)\n",
    "    # st.write(page)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    # Bitcoin Magazine Scrapper (DONE)\n",
    "    if 'bitcoinmagazine.com' in URL :\n",
    "        date = soup.find('time')\n",
    "        date = str(date)[:42]\n",
    "        date = re.sub('<time datetime=\"','',date)\n",
    "        date = date[:-1]\n",
    "\n",
    "        text = []\n",
    "        for data in soup.find_all('p') :\n",
    "            text.append(data.get_text())\n",
    "            \n",
    "        if text :\n",
    "            dates.append(date)\n",
    "            articles.append((''.join(text)))\n",
    "            \n",
    "        # st.write('Bitcoin Magazine', page, len(text), date)\n",
    "        print('BitcoinMagazine', page, date, len(text))\n",
    "\n",
    "    # CoinDesk Scrapper (DONE)\n",
    "    if 'coindesk.com' in URL :\n",
    "        date = soup.find_all('span', {'class':'typography__StyledTypography-owin6q-0 dHSCiD'})\n",
    "        date = re.sub(',|at|UTC', '', date[279].text)\n",
    "        date = re.sub(' a.m.', ' AM', date)\n",
    "        date = re.sub(' p.m.', ' PM', date)\n",
    "        date = re.sub('  ', ' ', date)\n",
    "\n",
    "        result = soup.find_all('p')\n",
    "\n",
    "        text = []\n",
    "        for r in result :\n",
    "            r = str(r)\n",
    "            if (r.startswith('<p>')) and (r.endswith('</p>')) :\n",
    "                r = re.sub('<p>|</p>|<b>|</b>|<a |</a>|</p>|<i>|</i>|<br>|</br>|<br/>|<|>','',r)\n",
    "                text.append(r)\n",
    "                \n",
    "        if text :\n",
    "            dates.append(date)\n",
    "            articles.append(''.join(text))\n",
    "\n",
    "        # st.write('CoinDesk', page, len(text), date)\n",
    "        print('CoinDesk', page, date, len(text))\n",
    "\n",
    "    # CoinTelegraph Scrapper\n",
    "    if 'cointelegraph.com' in URL :\n",
    "        date = soup.find_all('span', {'class':'typography__StyledTypography-owin6q-0 dHSCiD'})\n",
    "        date = re.sub(',|at|UTC', '', date[279].text)\n",
    "        date = re.sub(' a.m.', ' AM', date)\n",
    "        date = re.sub(' p.m.', ' PM', date)\n",
    "        date = re.sub('  ', ' ', date)\n",
    "\n",
    "        text = []\n",
    "        result = soup.find_all('p', text=True)\n",
    "        for r in result :\n",
    "            r = str(r)\n",
    "            if (r.startswith('<p>')) and (r.endswith('</p>')) :\n",
    "                r = re.sub('<p>|</p>|<b>|</b>|<a |</p>','',r)\n",
    "                text.append(r)\n",
    "\n",
    "        if text :\n",
    "            articles.append(''.join(text))\n",
    "            dates.append(date)\n",
    "        \n",
    "        # st.write('CoinTelegraph', page, len(text), date)\n",
    "        print('CoinTelegraph', page, date, len(text))\n",
    "\n",
    "    # CryptoSlate Scrapper (DONE)\n",
    "    if 'cryptoslate.com' in URL :\n",
    "        date = soup.find('span', class_='post-date')\n",
    "        date = str(date)\n",
    "        date = re.sub('<span class=\"post-date\">| UTC</span></span>|<span class=\"time\">', '', date)\n",
    "        date = re.sub('at', '', date)\n",
    "        \n",
    "        result = soup.find_all('p')\n",
    "        text = []\n",
    "        result = soup.find_all('p')\n",
    "        for r in result :\n",
    "            r = str(r)\n",
    "            r = re.sub('<p>|</p>|<span>|</span>|<p class=\"post-subheading\">|<p class=\"image-credit\">|<a>|</a>', '', str(r))\n",
    "            r = re.sub('<script>|</script>|[|]', '', r)\n",
    "            text.append(r)\n",
    "\n",
    "        if text :\n",
    "            articles.append(''.join(text))\n",
    "            dates.append(date)\n",
    "\n",
    "        # st.write('CryptoSlate', page, len(text), date)\n",
    "        print('CryptoSlate', page, date, len(text))\n",
    "\n",
    "    # Yahoo Scrapper (DONE)\n",
    "    if 'yahoo.com' in URL :\n",
    "        date = soup.find('time')\n",
    "\n",
    "        date = str(date)\n",
    "        date = date.replace('\"','')\n",
    "        date = re.sub('<time class=caas-attr-meta-time datetime=|>|</time>', '',date)\n",
    "        date = date[:24]\n",
    "        \n",
    "        text = []\n",
    "        result = soup.find_all('p', text=True)\n",
    "        for r in result :\n",
    "            r = str(r)\n",
    "            r = re.sub('\"|</p>|<p>','', r)\n",
    "            if r.startswith('<p class=M(0) C($summaryColor) Fz(14px) Lh(1.43em) LineClamp(3,60px)>') :\n",
    "                r = r[69:]\n",
    "            text.append(r)\n",
    "        \n",
    "        if text :\n",
    "            articles.append(''.join(text))\n",
    "            dates.append(date)\n",
    "\n",
    "        # st.write('Yahoo', page, len(text), date)\n",
    "        print('Yahoo', page, date, len(text))\n",
    "\n",
    "    # Forbes Scrapper (DONE)\n",
    "    if 'forbes' in URL :\n",
    "        URL = link\n",
    "        # Request access to the URL\n",
    "        page = requests.get(URL, headers=headers)\n",
    "\n",
    "        # Parse the html using BeautifulSoup for scrapping\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        date = soup.find_all('time')\n",
    "        date = str(date[18]) + str(date[19])\n",
    "        date = re.sub('<time>|</time>','', date)\n",
    "        date = re.sub(',',' ', date)\n",
    "        date = re.sub('  ',' ',date)[:-3]\n",
    "        # print(date)\n",
    "        \n",
    "        text = []\n",
    "        result = soup.find_all('p')\n",
    "        for r in result :\n",
    "            r = str(r)\n",
    "            r = re.sub('\"|</p>|<p>','', r)\n",
    "            r = re.sub('<p class=color-body light-text>', '',r)\n",
    "            text.append(r)\n",
    "        \n",
    "        if text :\n",
    "            articles.append(''.join(text))\n",
    "            dates.append(date)\n",
    "\n",
    "        # st.write('Forbes', page, len(text), date)\n",
    "        print('Forbes', page, date, len(text))\n",
    "\n",
    "    # Nulltx Scrapper (DONE)\n",
    "    if 'nulltx.com' in URL :\n",
    "        date = soup.find('time')\n",
    "        date = re.sub('<time class=\"entry-date updated td-module-date\" datetime=\"|</time>','',str(date))\n",
    "        date = date[:25]\n",
    "        \n",
    "        text = []\n",
    "        result = soup.find_all('p')\n",
    "        for r in result :\n",
    "            r = str(r)\n",
    "            r = re.sub('<p>|</p>|<strong>|</strong>', '', r)\n",
    "            r = re.sub('<p class=\"comment-form-cookies-consent\"><input id=\"wp-comment-cookies-consent\" name=\"wp-comment-cookies-consent\" type=\"checkbox\" value=\"yes\"><label for=\"wp-comment-cookies-consent\">Save my name, email, and website in this browser for the next time I comment.</label></input>','',r)\n",
    "            r = re.sub('<p class=\"form-submit\"><input class=\"submit\" id=\"submit\" name=\"submit\" type=\"submit\" value=\"Post Comment\"> <input id=\"comment_post_ID\" name=\"comment_post_ID\" type=\"hidden\" value=\"103352\">','',r)\n",
    "            r = re.sub('<em>Image Source: Vintage Tone/<a href=\"http://shutterstock.com/\" rel=\"noopener nofollow\" target=\"_blank\">Shutterstock.com</a></em>','',r)\n",
    "            r = re.sub('<input id=\"comment_parent\" name=\"comment_parent\" type=\"hidden\" value=\"0\">|</input></input></input>','',r)\n",
    "            r = re.sub('nulltx.com is part of the Null Transaction PR media group.','',r)\n",
    "            r = r.replace('\\n\\n','')\n",
    "            text.append(r)\n",
    "\n",
    "        if text :\n",
    "            articles.append(''.join(text))\n",
    "            dates.append(date)\n",
    "\n",
    "        # st.write('NullTx', page, len(text), date)\n",
    "        print('NullTx', page, date, len(text))\n",
    "\n",
    "    # Blockonomi Scrapper (DONE)\n",
    "    if 'blockonomi.com' in URL :\n",
    "        date = soup.find('time', class_='post-date')\n",
    "        date = re.sub('<time class=\"post-date\" datetime=\"|</time>','',str(date))\n",
    "        date = date[:25]\n",
    "        \n",
    "        text = []\n",
    "        result = soup.find_all('p')\n",
    "        for r in result :\n",
    "            r = str(r)\n",
    "            r = re.sub('<p>|</p>|<strong>|</strong>|<br>|</br>|<br/>|<em>|</em>|<a>|</a>', '', r)\n",
    "            r = re.sub('<p class=\"toc_title\">|<p class=\"text author-bio\">|<p class=\"copyright\">','',r)\n",
    "            text.append(r)\n",
    "\n",
    "        if text :\n",
    "            articles.append(''.join(text))\n",
    "            dates.append(date)\n",
    "\n",
    "        # st.write('Blockonomi', page, len(text), date)\n",
    "        print('Blockonomi', page, date, len(text))\n",
    "    \n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.coindesk.com/markets/2021/08/04/bitcoin-stuck-below-40k-eyes-short-term-oversold-bounce/\n",
      "https://www.coindesk.com/markets/2022/01/31/first-mover-asia-crypto-finishes-bad-month-on-high-note/\n",
      "https://www.coindesk.com/markets/2022/02/01/hackers-move-383m-worth-of-bitcoin-from-2016-bitfinex-hack/\n",
      "https://bitcoinmagazine.com/business/at-home-bitcoin-mining-is-surging\n",
      "https://bitcoinmagazine.com/culture/why-should-i-care-about-bitcoin\n",
      "https://cryptoslate.com/whats-behind-bitcoins-sudden-plunge-to-40000/\n",
      "https://cryptoslate.com/fans-can-now-use-ethereum-to-tip-creators-on-twitter/\n",
      "https://finance.yahoo.com/news/forex-dollar-edges-higher-powell-140607366.html\n",
      "https://www.forbes.com/sites/ninabambysheva/2021/07/12/bitcoin-is-steady-as-it-braces-for-a-big-week/?sh=3a9ac8743ac6\n",
      "https://nulltx.com/with-bitcoin-and-ethereum-price-crashing-this-web3-coin-gained-over-1800-today/\n",
      "https://nulltx.com/with-bitcoin-price-crashing-these-3-cryptocurrencies-gained-over-200-today/\n",
      "https://blockonomi.com/whats-up-with-the-bitcoin-network/\n",
      "https://blockonomi.com/zest-protocol-guide/\n",
      "https://blockonomi.com/money-on-chain-brings-earning-to-bitcoin-holders-with-25-return/\n"
     ]
    }
   ],
   "source": [
    "links = pd.read_csv('link.csv', header=None)\n",
    "\n",
    "for link in links[0] :\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates), len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_df = pd.DataFrame({'Text':articles, 'DateTime':dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
